代码相关疑问：
1、	协方差计算是除以n还是n-1，这个导致课程代码PCA_numpy_detail.py与PCA_numpy.py在X值一样的情况下，结果不同。课件里看了下也是n-1，实际应该是样本数量n吧
2、	关于求特征值、特征向量。课件中A是2*2矩阵，算出特征值是2和5，同时算出2个对应的特征向量。但是通过PCA手写代码对课件2*2矩阵计算，特征值没问题是2和5，但是特征向量和课件的不一样，不过代入(A-λI)x=0是成立的（其中一个解是无限约等于0）
而且课件、代码计算出的特征向量是有规律的，每列值的比例是固定的，那么：如果存在向量A x=0，而且A=r*B（r是一个随机倍数），那么可以满足(r*A)x=r*AX=0，即存在无数解使得A x=0，只要在已知解A基础上乘以随意一个倍数r即可
3、	课程代码PCA_numpy.py最终计算结果错误，X*特征向量，X应该是最初的矩阵，实际代码中X是中心化后的值
4、	课程代码PCA_sklearn.py中sklearn计算的PCA结果与手写PCA算法结果不一样（也没有倍数关系）。查了下应该是sklearn内部使用了SVD（奇异值分解），没有直接用协方差
5、	鸢尾花代码，是通过sklearn计算后显示散点图，又试了下通过手写PCA方式计算后显示散点图。发现散点图显示基本一致，不一样的地方是1）坐标范围不一样（绝对值一样），sklearn计算的结果数据分布在0点两侧；2）Y值（第2列）取值是反的。基于该发现，应该是sklearn对数据做了平均值归一化，测试了下果然如此，Y值*-1也还原了sklearn的效果。这样问题4也解决了。
同时，可知PCA结果也不是唯一的，可以通过各种归一化进行数据处理，不过应该是不会影响了数据的特征分布。

个人推导：
1、	关于为啥要计算(A-λE)x =0，为啥要计算|A-λE|=0？
(A-λE)x =0，x是非0向量，因此我们不是简单的寻找A-λE=0，它其实也是一个非0向量。|A-λE|才是一个标量。
X乘以X的逆矩阵=1，那么要求x可以给(A-λE)x =0两边都乘以A-λE的逆矩阵，这个时候变为了x=0*(A-λE)-1，但是这是不成立的，前面写了x是非0向量。因此A-λE只能是奇异矩阵（没有逆矩阵），即必须满足|A-λE|=0
