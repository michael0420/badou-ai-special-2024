{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15ecd083",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b82071",
   "metadata": {},
   "source": [
    "设定用于训练和评估的样本总数\n",
    "num_examples_pre_epoch_for_train = 50000\n",
    "num_examples_pre_epoch_for_eval = 10000\n",
    "定义读取cifar10的函数 ----->读取目标文件的内容\n",
    "定义数据预处理的函数 ----->图像增强"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a193628c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_cifar10(file_queue):\n",
    "    #用来读取cifar10图片信息并进行切割区分\n",
    "    \n",
    "    class CIFAR10Record(object):\n",
    "        pass\n",
    "    #定义一个空类，用于返回读取的Cifar10数据\n",
    "    result = CIFAR10Record()\n",
    "    \n",
    "    label_bytes = 1\n",
    "    result.height = 32\n",
    "    result.width = 32\n",
    "    result.channel = 3\n",
    "    #输入的图像数据 label bytes由于分类为10所以占位是1（0-9）\n",
    "    \n",
    "    images_bytes = result.height * result.width * result.channel\n",
    "    record_bytes = label_bytes+images_bytes\n",
    "    #计算图像占位和总体占位\n",
    "    \n",
    "    reader = tf.FixedLengthRecordReader(record_bytes = record_bytes)\n",
    "    #读取固定长度\n",
    "\n",
    "    result.key, value = reader.read(filename_queue) #从inputs函数中获取的filename_queue\n",
    "    record_bytes=tf.decode_raw(value,tf.uint8) \n",
    "    \n",
    "    result.label = tf.strided_slice(record_bytes,[0], [label_bytes])\n",
    "    result.label = tf.cast(result.label, tf.int32)\n",
    "\n",
    "    result.image = tf.strided_slice(record_bytes,[label_bytes],[label_bytes + image_bytes] )\n",
    "    result.image = tf.reshape(result.channel, result.height, result.width)\n",
    "    result.image = tf.transpose(result.image, [1,2,0])\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f76c5d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inputs(data_dir, batch_size, distorted): #需要输入，数据集地址，批大小，distorted= True or False\n",
    "    \n",
    "\n",
    "    filename = [os.path.join(data_dir, 'data_batch_%d.bin'%i)for i in range(1,6)]\n",
    "    #['Cifar_data/cifar-10-batches-bin\\\\data_batch_1.bin', \n",
    "    #'Cifar_data/cifar-10-batches-bin\\\\data_batch_2.bin',\n",
    "    #'Cifar_data/cifar-10-batches-bin\\\\data_batch_3.bin', \n",
    "    #'Cifar_data/cifar-10-batches-bin\\\\data_batch_4.bin', \n",
    "    #'Cifar_data/cifar-10-batches-bin\\\\data_batch_5.bin']\n",
    "    \n",
    "    filename_queue = tf.train.string_input_producer(filenames, shuffle=True)\n",
    "    #创建输入队列\n",
    "    \n",
    "    read_input = read_cifar10(filename_queue)\n",
    "    #根据自定义read_cifar10函数来读取数据集信息\n",
    "    \n",
    "    reshaped_image = tf.cast(read_input.unit8image, tf.float32)\n",
    "    #将读取的信息转换成float32格式\n",
    "    \n",
    "    num_examples_per_epoch = num_examples_pre_epoch_for_train\n",
    "    #指定用于训练的图像数量\n",
    "    \n",
    "    if distorted != None: #如果distorted不为空，则进行数据增强处理\n",
    "        '''\n",
    "        数据剪切，tf.random.crop\n",
    "        左右翻转 tf.image.random_flip_left_right()\n",
    "        随机对比度调整 tf.image.random_contrast()\n",
    "        标准化图片操作tf.image.per_image_standardization()\n",
    "        '''\n",
    "        cropped_image = tf.random.crop(reshaped_image, [24,24,3])\n",
    "        flipped_image = tf.image.random_flip_left_right(cropped_image)\n",
    "        adjusted_image = tf.image.random_contrast(flipped_image, max_delta = 0.8)\n",
    "        lightten_image = tf.image.random_brightness(adjusted_image, lower=0.2, upper=0.8)\n",
    "        normalized_image = tf.image.per_image_standardization(lightten_image)\n",
    "        \n",
    "        normalized_image.set_shae([24,24,3])\n",
    "        read_input.label.set_shape([1])\n",
    "        \n",
    "        min_queue_examples = int(num_examples_pre_epoch_for_eval*0.4)\n",
    "        print('')\n",
    "        \n",
    "        images_train, labels_train = tf.train.shuffle_batch([normalized_image, read_input.label], \n",
    "                                                                batch_size=batch_size, num_threads=16,\n",
    "                                                                capacity = min_queue_examples + 3*batch_size,\n",
    "                                                                min_after_dequeue = min_queue_examples)\n",
    "        \n",
    "        return image_train, tf.reshape(labels_train, [batch_size])\n",
    "    \n",
    "    else:\n",
    "        #测试图片不需要进行数据增强，但是需要resize和normalize\n",
    "        resized_image = tf.image.resize_image_with_crop_or_pad(reshaped_image,24,24)\n",
    "        normalized_image = tf.image.per_image_standarlization(resized_image)\n",
    "        \n",
    "        normalized_image.set_shape([24,24,3])\n",
    "        read_input.label.set_shape([1])\n",
    "        \n",
    "        min_queue_examples = int(num_examples_pre_epoch_for_eval*0.4)\n",
    "        print('')\n",
    "        \n",
    "        images_test,labels_test = tf.train.batch([normalized_image, read_input.label], \n",
    "                                                                batch_size=batch_size, num_threads=16,\n",
    "                                                                capacity = min_queue_examples + 3*batch_size,\n",
    "                                                                min_after_dequeue = min_queue_examples)\n",
    "        \n",
    "        return images_test, tf.reshape(labels_test, [batch_size])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bb5e210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cifar_data/cifar-10-batches-bin\\\\data_batch_1.bin', 'Cifar_data/cifar-10-batches-bin\\\\data_batch_2.bin', 'Cifar_data/cifar-10-batches-bin\\\\data_batch_3.bin', 'Cifar_data/cifar-10-batches-bin\\\\data_batch_4.bin', 'Cifar_data/cifar-10-batches-bin\\\\data_batch_5.bin']\n"
     ]
    }
   ],
   "source": [
    "data_dir=\"Cifar_data/cifar-10-batches-bin\"\n",
    "filenames=[os.path.join(data_dir,\"data_batch_%d.bin\"%i)for i in range(1,6)]\n",
    "print(filenames)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
