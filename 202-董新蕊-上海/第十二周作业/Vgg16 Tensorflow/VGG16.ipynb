{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "affea732",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65ff9430",
   "metadata": {},
   "outputs": [],
   "source": [
    "slim = tf.contrib.slim\n",
    "#创建slim对象，slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9cdc93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg_16 (inputs, num_classes = 1000, is_training = True, dropout = 0.5, spatial_squeeze = True, scope = 'vgg_16'):\n",
    "    with tf.variable_scope (scope, 'vgg_16', [inputs]):\n",
    "        # conv1两次[3,3]卷积网络，输出的特征层为64，输出为(224,224,64)\n",
    "        # 2X2最大池化，输出net为(112,112,64)\n",
    "        net = slim.repeat(inputs, 2, slim.conv2d, 64, [3,3], scope = 'conv1')\n",
    "        net = slim.maxpooling(net, [2,2], scope = 'pool1')\n",
    "        # conv2两次[3,3]卷积网络，输出的特征层为128，输出net为(112,112,128)\n",
    "        # 2X2最大池化，输出net为(56,56,128)\n",
    "        net = slim.repeat(net, 2, slim.conv2d, 128, [3,3], scope = 'conv2')\n",
    "        net = slim.maxpooling(net, [2,2], scope = 'pool2')\n",
    "        # conv3三次[3,3]卷积网络，输出的特征层为256，输出net为(56,56,256)\n",
    "        # 2X2最大池化，输出net为(28,28,256)\n",
    "        net = slim.repeat(net, 3, slim.conv2d, 256, [3,3], scope = 'conv3')\n",
    "        net = slim.maxpooling(net, [2,2], scope = 'pool3')        \n",
    "        # conv3三次[3,3]卷积网络，输出的特征层为256，输出net为(28,28,512)\n",
    "        # 2X2最大池化，输出net为(14,14,512)\n",
    "        net = slim.repeat(net, 3, slim.conv2d, 512, [3,3], scope = 'conv4')\n",
    "        net = slim.maxpooling(net, [2,2], scope = 'pool4')     \n",
    "        # conv3三次[3,3]卷积网络，输出的特征层为256，输出net为(14,14,512)\n",
    "        # 2X2最大池化，输出net为(7,7,512)\n",
    "        net = slim.repeat(net, 3, slim.conv2d, 256, [3,3], scope = 'conv5')\n",
    "        net = slim.maxpooling(net, [2,2], scope = 'pool5')           \n",
    "        # 利用卷积的方式模拟全连接层，效果等同，输出net为(1,1,4096)\n",
    "        net = slim.conv2d(net, 4096, [7,7],padding = 'VALID', scope = 'fc6')\n",
    "        net = slim.dropout(net, dropout,is_training = is_training,  scope = 'dropout6')\n",
    "        # 利用卷积的方式模拟全连接层，效果等同，输出net为(1,1,4096)\n",
    "        net = slim.conv2d(net, 4096, [1,1],scope = 'fc7')\n",
    "        net = slim.dropout(net, dropout,is_training = is_training,  scope = 'dropout7')        \n",
    "        # 利用卷积的方式模拟全连接层，效果等同，输出net为(1,1,1000)\n",
    "        net = slim.conv2d(net, 1000, [1,1],scope = 'fc7')\n",
    "        # 由于用卷积的方式模拟全连接层，所以输出需要平铺\n",
    "        net = slim.conv2d(net, num_classes, [1, 1],\n",
    "                        activation_fn=None,\n",
    "                        normalizer_fn=None,\n",
    "                        scope='fc8')\n",
    "        if spatial_squeeze:\n",
    "            net = tf.squeeze(net, [1,2], name = 'squeeze9') \n",
    "            #去除维度大小为1的，留下batchsize和channels 注意：只能去掉1的，如果是2X2就要用reshape或者flatten\n",
    "            \n",
    "        return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b67da4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "with tf.compat.v1.variable_scope(\"foo\"):\n",
    "    with tf.compat.v1.variable_scope(\"bar\"):\n",
    "        v = tf.compat.v1.get_variable(\"v\", [1])\n",
    "        assert v.name == \"foo/bar/v:0\"\n",
    "# 测验variable_scope功能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39793cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
