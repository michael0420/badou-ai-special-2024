{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6f4e3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, DepthwiseConv2D, Activation, BatchNormalization, Conv2D, GlobalAveragePooling2D, GlobalMaxPooling2D, Reshape, Dropout\n",
    "from keras.applications.imagenet_utils import decode_predictions\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "54d72a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def  _conv_block (inputs, filters_num, kernel = (3,3), strides = (1,1)):\n",
    "    x = Conv2D(filters_num, kernel, padding = 'same', \n",
    "               use_bias = False, strides = strides, name = 'conv1')(inputs)\n",
    "    x = BatchNormalization(name = 'conv1_bn')(x)\n",
    "    x = Activation(relu6, name = 'conv1_relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def _depthwise_conv_block (inputs, pointwise_conv_filters_num, depth_multiplier = 1, strides = (1,1), block_id = 1):\n",
    "    \n",
    "    \n",
    "    '''\n",
    "        keras.layers.DepthwiseConv2D(kernel_size, strides=(1, 1), \n",
    "                                 padding='valid', depth_multiplier=1, \n",
    "                                 data_format=None, dilation_rate=(1, 1), \n",
    "                                 activation=None, use_bias=True, \n",
    "                                 depthwise_initializer='glorot_uniform', \n",
    "                                 bias_initializer='zeros', \n",
    "                                 depthwise_regularizer=None, \n",
    "                                 bias_regularizer=None, activity_regularizer=None, \n",
    "                                 depthwise_constraint=None, bias_constraint=None)\n",
    "    '''\n",
    "    x = DepthwiseConv2D((3,3), strides = strides, depth_multiplier = depth_multiplier, padding = 'same',\n",
    "                        use_bias=False, name = 'conv_dw_%d' % block_id)(inputs)\n",
    "    x = BatchNormalization(name = 'conv_dw_%d_bn' % block_id)(x)\n",
    "    x = Activation(relu6, name = 'conv_dw_%d_relu' % block_id)(x)\n",
    "    \n",
    "    x = Conv2D(pointwise_conv_filters_num, (1,1), strides = (1,1), padding = 'same',use_bias=False,\n",
    "                name = 'conv_pw_%d' % block_id)(x)\n",
    "    x = BatchNormalization(name = 'conv_pw_%d_bn' % block_id)(x)\n",
    "    x = Activation(relu6, name = 'conv_pw_%d_relu' % block_id)(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def MobileNet(input_shape, classes, dropout, depth_multiplier = 1):\n",
    "    \n",
    "    img_input = Input(shape=input_shape)\n",
    "\n",
    "    # 224,224,3 -> 112,112,32\n",
    "    x = _conv_block(img_input, 32, strides=(2, 2))\n",
    "    print(x.shape)\n",
    "\n",
    "    # 112,112,32 -> 112,112,64\n",
    "    x = _depthwise_conv_block(x, 64, depth_multiplier, block_id=1)\n",
    "    print(x.shape)\n",
    "    # 112,112,64 -> 56,56,128\n",
    "    x = _depthwise_conv_block(x, 128, depth_multiplier,\n",
    "                              strides=(2, 2), block_id=2)\n",
    "    print(x.shape)\n",
    "    # 56,56,128 -> 56,56,128\n",
    "    x = _depthwise_conv_block(x, 128, depth_multiplier, block_id=3)\n",
    "    print(x.shape)\n",
    "\n",
    "    # 56,56,128 -> 28,28,256\n",
    "    x = _depthwise_conv_block(x, 256, depth_multiplier,\n",
    "                              strides=(2, 2), block_id=4)\n",
    "    print(x.shape)\n",
    "    \n",
    "    # 28,28,256 -> 28,28,256\n",
    "    x = _depthwise_conv_block(x, 256, depth_multiplier, block_id=5)\n",
    "    print(x.shape)\n",
    "\n",
    "    # 28,28,256 -> 14,14,512\n",
    "    x = _depthwise_conv_block(x, 512, depth_multiplier,\n",
    "                              strides=(2, 2), block_id=6)\n",
    "    print(x.shape)\n",
    "    \n",
    "    # 14,14,512 -> 14,14,512\n",
    "    x = _depthwise_conv_block(x, 512, depth_multiplier, block_id=7)\n",
    "    x = _depthwise_conv_block(x, 512, depth_multiplier, block_id=8)\n",
    "    x = _depthwise_conv_block(x, 512, depth_multiplier, block_id=9)\n",
    "    x = _depthwise_conv_block(x, 512, depth_multiplier, block_id=10)\n",
    "    x = _depthwise_conv_block(x, 512, depth_multiplier, block_id=11)\n",
    "    print(x.shape)\n",
    "\n",
    "    # 14,14,512 -> 7,7,1024\n",
    "    x = _depthwise_conv_block(x, 1024, depth_multiplier,\n",
    "                              strides=(2, 2), block_id=12)\n",
    "    print(x.shape)\n",
    "    x = _depthwise_conv_block(x, 1024, depth_multiplier, block_id=13)\n",
    "    print(x.shape)\n",
    "\n",
    "    # 7,7,1024 -> 1,1,1024\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    print(x.shape)\n",
    "    x = Reshape((1, 1, 1024), name='reshape_1')(x)\n",
    "    print(x.shape)\n",
    "    x = Dropout(dropout, name='dropout')(x)\n",
    "    print(x.shape)\n",
    "    x = Conv2D(classes, (1, 1),padding='same', name='conv_preds')(x)\n",
    "    print(x.shape)\n",
    "    x = Activation('softmax', name='act_softmax')(x)\n",
    "    print(x.shape)\n",
    "    x = Reshape((classes,), name='reshape_2')(x)\n",
    "    print(x.shape)\n",
    "\n",
    "    inputs = img_input\n",
    "\n",
    "    model = Model(inputs, x, name='mobilenet_1_0_224_tf')\n",
    "    model_name = 'mobilenet_1_0_224_tf.h5'\n",
    "    model.load_weights(model_name)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "54a95376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 112, 112, 32)\n",
      "(?, 112, 112, 64)\n",
      "(?, 56, 56, 128)\n",
      "(?, 56, 56, 128)\n",
      "(?, 28, 28, 256)\n",
      "(?, 28, 28, 256)\n",
      "(?, 14, 14, 512)\n",
      "(?, 14, 14, 512)\n",
      "(?, 7, 7, 1024)\n",
      "(?, 7, 7, 1024)\n",
      "(?, 1024)\n",
      "(?, 1, 1, 1024)\n",
      "(?, 1, 1, 1024)\n",
      "(?, 1, 1, 1000)\n",
      "(?, 1, 1, 1000)\n",
      "(?, 1000)\n",
      "input image shape (1, 224, 224, 3)\n",
      "386\n",
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n",
      "40960/35363 [==================================] - 0s 4us/step\n",
      "Predicted [[('n02504458', 'African_elephant', 0.7636115)]]\n"
     ]
    }
   ],
   "source": [
    "def relu6(x):\n",
    "    return K.relu(x, max_value = 6)\n",
    "    \n",
    "def preprocess_input(x):\n",
    "    x /= 255.\n",
    "    x -= 0.5\n",
    "    x *= 2\n",
    "    return x\n",
    "\n",
    "if __name__ =='__main__':\n",
    "\n",
    "    model = MobileNet(input_shape = (224,224,3),classes = 1000, dropout = 1e-3)\n",
    "    \n",
    "    #读取图片信息， 图片地址，load图片，nparray\n",
    "    img_path = 'elephant.jpg'\n",
    "    img = image.load_img(img_path, target_size = (224,224))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis = 0)\n",
    "    x = preprocess_input(x)\n",
    "    print('input image shape', x.shape)\n",
    "    \n",
    "    preds = model.predict(x)\n",
    "    print(np.argmax(preds))\n",
    "    print ('Predicted', decode_predictions(preds,1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee8247f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow] *",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
